model {
  name: "dnn"
  objective_function: "categorical_cross_entropy"
  metric: "categorical_accuracy"
  data_layout: "data_parallel"
  mini_batch_size: 192
  num_epochs: 10
  num_parallel_readers: 1
  procs_per_model: 0
  use_cudnn: false
  num_gpus: -1

  ###################################################
  # Optimzer
  ###################################################
  optimizer {
    name: "adagrad"
    learn_rate: 0.01
    eps: 1e-8  #used for adagrad, adam, hypergradient_adam
    #momentum: 0.9 #used for sgd
    #decay: 0.5    #used for rmsprop, sgd
    #nesterov: true #used for sgd
    #beta1: 0.9 # used for adam, hypergradient_adam
    #beta2: 0.99 # used for adam, hypergradient_adam
  }

  ###################################################
  # Callbacks
  ###################################################
  callback {
    print {
      interval: 1
    }
  }
  callback {
    timer {
      dir: "none"
    }
  }
  callback {
    summary {
      dir: "none"
      interval: 1
    }
  }
  callback {
    debug {
      phase: "train"
    }
  }

  ###################################################
  # start of layers
  ###################################################

  #######
  # INPUT
  #######
  layer {
    index: 1
    parent: 1
    data_layout: "data_parallel"
    input_distributed_minibatch_parallel_io {
    }
  }

  #################
  # FULLY_CONNECTED
  #################
  layer {
    index: 2
    parent: 1
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 100
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  ######
  # RELU
  ######
  layer {
    index: 3
    parent: 2
    data_layout: "data_parallel"
    relu {
      num_neurons: 100
    }
  }

  #########
  # DROPOUT
  #########
  layer {
    index: 4
    parent: 3
    data_layout: "data_parallel"
    dropout {
      num_neurons: 100
      keep_prob: -1.0
    }
  }

  #################
  # FULLY_CONNECTED
  #################
  layer {
    index: 5
    parent: 4
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 30
      weight_initialization: "glorot_uniform"
      has_bias: true
    }
  }

  #######
  # RELU
  #######
  layer {
    index: 6
    parent: 5
    data_layout: "data_parallel"
    relu {
      num_neurons: 30
    }
  }

  ##########
  # DROPOUT
  ##########
  layer {
    index: 7
    parent: 6
    data_layout: "data_parallel"
    dropout {
      num_neurons: 30
      keep_prob: -1.0
    }
  }

  #################
  # FULLY_CONNECTED
  #################
  layer {
    index: 8
    parent: 7
    data_layout: "data_parallel"
    fully_connected {
      num_neurons: 10
      weight_initialization: "glorot_uniform"
      has_bias: false
    }
  }

  #########
  # SOFTMAX
  #########
  layer {
    index: 9
    parent: 8
    data_layout: "data_parallel"
    softmax {
      num_neurons: 10
      weight_initialization: "glorot_uniform"
    }
  }

  #########
  # TARGET
  #########
  layer {
    index: 10
    parent: 9
    data_layout: "data_parallel"
    target_distributed_minibatch_parallel_io {
      shared_data_reader: true
    }
  }

  ###################################################
  # end of layers
  ###################################################
}
