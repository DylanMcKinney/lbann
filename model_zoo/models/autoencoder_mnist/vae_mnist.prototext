model {
  name: "directed_acyclic_graph_model"
  data_layout: "model_parallel"
  mini_batch_size: 100 
  block_size: 256
  num_epochs: 50
  num_parallel_readers: 0
  procs_per_model: 0
  num_gpus: -1

  ###################################################
  # Objective function
  ###################################################

  objective_function {
    binary_cross_entropy {}
    layer_term {
      scale_factor: 1.0
      layer: "kl_divergence"
    }
    l2_weight_regularization {
      scale_factor: 1e-4
    }
  }

  ###################################################
  # Metrics
  ###################################################

  metric { mean_squared_error {} }

  ###################################################
  # Callbacks
  ###################################################
  callback {
    print {
      interval: 1
    }
  }
  callback { timer {} }
  callback {
    dump_activations {
      basename: "dump_acts/"
      layer_names: "relu1 sum"
    }
  }
  callback {
    save_images {
      image_dir: "images_"
      extension: "png"
    }
  }

  ###################################################
  # start of layers
  ###################################################

  # Data
  layer {
    name: "data"
    data_layout: "model_parallel"
    input {
      io_buffer: "distributed"
    }
  }

  # Encoder
  layer {
    parents: "data"
    name: "encode1"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 256
      weight_initialization: "he_normal"
      has_bias: true
    }
  }
  layer {
    parents: "encode1"
    name: "encode1_relu"
    data_layout: "model_parallel"
    relu {}
  }
  layer {
    parents: "encode1_relu"
    name: "z_mean"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 2
      weight_initialization: "glorot_normal"
      has_bias: true
    }
  }
  layer {
    parents: "encode1_relu"
    name: "z_log_sigma"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 2
      weight_initialization: "glorot_normal"
      has_bias: true
    }
  }

  # KL divergence
  layer {
    name: "kl_one"
    data_layout: "model_parallel"
    constant {
      value: 1.0
      num_neurons: "2"
    }
  }
  layer {
    parents: "z_mean"
    name: "kl_z_mean2"
    data_layout: "model_parallel"
    power {
      exponent: 2.0
    }    
  }
  layer {
    parents: "z_log_sigma"
    name: "kl_exp"
    data_layout: "model_parallel"
    exponential {}
  }
  layer {
    parents: "kl_one z_log_sigma kl_z_mean2 kl_exp"
    name: "kl_entrywise"
    data_layout: "model_parallel"
    sum {
      scaling_factors: "-0.5 -0.5 0.5 0.5"
    }
  }
  layer {
    parents: "kl_entrywise"
    name: "kl_sum"
    data_layout: "data_parallel"
    reduction {
      mode: "sum"
    }
  }
  layer {
    parents: "kl_sum"
    name: "kl_divergence"
    data_layout: "data_parallel"
    evaluation {}
  }

  # Sample from latent space
  layer {
    parents: "z_log_sigma"
    name: "sample_half"
    data_layout: "model_parallel"
    sum {
      scaling_factors: "0.5"
    }    
  }
  layer {
    parents: "sample_half"
    name: "sample_exp"
    data_layout: "model_parallel"
    exponential {}
  }
  layer {
    name: "sample_noise"
    data_layout: "model_parallel"
    noise {
      noise_factor: 1.0
      num_neurons: "2"
    }
  }
  layer {
    parents: "sample_exp sample_noise"
    name: "sample_exp_noise"
    data_layout: "model_parallel"
    hadamard {}
  }
  layer {
    parents: "z_mean sample_exp_noise"
    name: "sample"
    data_layout: "model_parallel"
    sum {}
  }

  # Decoder
  layer {
    parents: "sample"
    name: "decode1"
    data_layout: "model_parallel"
    fully_connected {
      num_neurons: 256
      weight_initialization: "he_normal"
      has_bias: true
    }
  }
  layer {
    parents: "decode1"
    name: "relu2"
    data_layout: "model_parallel"
    relu {}
  }
  layer {
    parents: "relu2"
    name: "decode0"
    data_layout: "model_parallel"
    num_neurons_from_data_reader: true
    fully_connected {
      weight_initialization: "glorot_normal"
      has_bias: true
    }
  }
  layer {
    parents: "decode0"
    name: "sigmoid"
    data_layout: "model_parallel"
    sigmoid {
    }
  }

  # Reconstruction
  layer {
    parents: "sigmoid"
    name: "reconstruction"
    data_layout: "model_parallel"
    reconstruction {
      original_layer: "data"
    }
  }

  ###################################################
  # end of layers
  ###################################################
}
