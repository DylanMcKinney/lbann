syntax = "proto3";

package lbann_data;

message LbannPB {
  DataReader data_reader = 1; 
  Model model = 2; 
  Optimizer optimizer = 3;
}

//========================================================================
// start of DataReaders
//========================================================================
message DataReader {
  int64 max_par_io_size = 1;
  repeated Reader reader = 2;
}

message Reader {
  string name = 1; //mnist, nci, nci_regression, cnpy, imagenet
  string role = 3; //train, test
  bool shuffle = 4;
  string data_filedir = 5;
  string data_filename = 6;
  string label_filename = 7;
  double train_or_test_percent = 8;
  double validation_percent = 9;
  bool firstN = 10;
  int64 max_sample_count = 11;
  double percent_of_data_to_use = 12;
  ImagePreprocessor image_preprocessor = 13;
}

message ImagePreprocessor {
  bool scale = 12;
  bool subtract_mean = 13;
  bool unit_variance = 14;
  bool z_score = 15;
  bool horizontal_flip = 16;
  bool vertical_flip = 17;
  double rotation = 18;
  double horizontal_shift = 19;
  double vertical_shift = 20;
  double shear_range = 21;
  bool disable_augmentation = 22;
}

//========================================================================
// end of DataReaders
//========================================================================

message Model {
  string name = 1; //dnn, greedy_layerwise_autoencoder
  string objective_function = 2; //categorical_cross_entropy, mean_squared_error
  repeated string metric = 5; //categorical_accuracy, mean_squared_error
  string data_layout = 6;

  int64 mini_batch_size = 12;
  int64 num_epochs = 4;
  int64 block_size = 50;
  int64 procs_per_model = 51;
  int64 num_gpus = 53;
  int64 evaluation_frequency = 54;
  int64 num_parallel_readers = 100;

  //use cudnn_manager, if use_cudnn=true AND lbann was compiled with cudnn support
  bool use_cudnn = 8;


  repeated Layer layer = 10;

  // checknan, debug, dump_activations, etc;
  // for complete list, see: lbann/include/lbann/callbacks
  repeated Callback callback = 20; 

  //checkpointing
  string checkpoint_dir = 30;
  int64 checkpoint_epochs = 31;
  int64 checkpoint_steps = 32;
  double checkpoint_secs = 33;
}

message Optimizer {
  //adagrad, rmsprop, adam, hypergradient_adam, sgd
  string name = 1;
  double learn_rate = 2;
  double momentum = 3; //sgd
  double decay = 4;    //rmsprop, sgd
  bool nesterov = 5;   //sgd
  double beta1 = 6;    //adam, hypergradient_adam
  double beta2 = 7;    //adam, hypergradient_adam
  double eps = 8;      //adagrad, adam, hypergradient_adam
}

message Callback {
   // a Callback should contain exactly one of the following
   CallbackPrint print = 1;
   CallbackTimer timer = 2;
   CallbackSummary summary = 3;
   CallbackDumpWeights dump_weights = 4;
   CallbackDumpActivations dump_activations = 5;
   CallbackDumpGradients dump_gradients = 6;
   CallbackImComm imcomm = 7;
   CallbackSaveImages save_images = 8;
   CallbackDebug debug = 9;
   CallbackAdaptiveLearningRate adaptive_learning_rate = 10;
   CallbackStepLearningRate step_learning_rate = 11;
   CallbackCustomLearningRate custom_learning_rate = 12;
}

message CallbackStepLearningRate {
  string layers = 1; //e.g: "1 5 6" use "10000" to apply to all layers
  int64 step = 2;
  double amt = 3;
}

message CallbackCustomLearningRate {
  //don't know how to support this, since it takes an std::function as an argument
}

message CallbackAdaptiveLearningRate {
  string layers = 1; //e.g: "1 5 6" use "10000" to apply to all layers
  int64 patience = 2;
  double amt = 3;
}

message CallbackSaveImages {
  string image_dir = 1;
  string extension = 2;
}

message CallbackPrint {
  int64 interval = 1; //default in lbann_callback_print.hpp is 1
}

message CallbackTimer {
  string dir = 1; //directory for the lbann_summary
}

message CallbackSummary {
  string dir = 1; //directory for the lbann_summary
  int64 interval = 2; //default in lbann_callback_summary.hpp is 1
}

message CallbackDumpWeights {
  string basename = 1;
  int64 interval = 2;
}

message CallbackDumpActivations {
  string basename = 1;
  int64 interval = 2;
}

message CallbackDumpGradients {
  string basename = 1;
  int64 interval = 2;
}

message CallbackImComm {
  string intermodel_comm_method = 1;
  string layers = 2; //e.g: "2 4 5"; use "10000" to apply to all layers
}

message CallbackDebug {
  string phase = 1;
}

//========================================================================
// start of Layer types
//========================================================================
//
// weight initialization should be one of: 
//    zero, uniform, normal, glorot_normal, he_normal, he_uniform
// see: lbann/include/lbann/lbann_base.hpp
//

message Layer {
   int64 index = 50; 
   int64 parent = 51;
   string data_layout = 52;

   // a Layer should contain exactly one of the following
   // (this may or may not be properly checked for in lbann_proto_common.cpp)

   // input Layers
   InputDistributedMiniBatchParallelIO input_distributed_minibatch_parallel_io = 2;
   InputPartitionedMiniBatchParallelIO input_partitioned_minibatch_parallel_io = 3;

   // transform Layers
   Pooling pooling = 12;

   // learning Layers
   FullyConnected fully_connected = 11;
   Convolution convolution = 13;

   // target Layers
   TargetDistributedMinibatchParallelIO target_distributed_minibatch_parallel_io = 18;
   TargetPartitionedMinibatchParallelIO target_partitioned_minibatch_parallel_io = 180;
   TargetReconstruction reconstruction = 22;

   // regularization Layers
   BatchNormalization batch_normalization = 19;
   LocalResponseNormalization local_response_normalization = 20;
   Dropout dropout = 21;
   SeluDropout selu_dropout = 229;

   // activation Layers
   Softmax softmax = 200;
   ELU elu = 30;
   ID id = 31;
   LeakyRelu leaky_relu = 32;
   Relu relu = 33;
   Sigmoid sigmoid = 34;
   SmoothRelu smooth_relu = 35;
   Softplus softplus = 36;
   Selu selu = 37;
   Tanh tanh = 38;
}

///////////////////////
// Activation Layers //
///////////////////////
message ELU {
  double alpha = 2; //default: 1.0; must be >= 0
}

message ID {
}

message LeakyRelu {
  double leak = 2; //default: 0.01
}

message Relu {
}

message Sigmoid {
}

message SmoothRelu {
}

message Softplus {
}

message Tanh {
}

message Selu {
  double alpha = 2;
  double scale = 3;
}

message Softmax {
  int64 num_neurons = 2;
  string weight_initialization = 3;
}

///////////////////////////
// Regularization Layers //
///////////////////////////
message BatchNormalization {
  int64 num_neurons = 1;
  double decay = 2; //default: 0.9
  double gamma = 3; //default: 1.0
  double beta = 4;  //default: 0.0
}

message SeluDropout {
  int64 num_neurons = 1;
  double keep_prob = 2; //default: 0.95
  double alpha = 3;     //default: 1.6732632423543772848170429916717
  double scale = 4;     //default: 1.0507009873554804934193349852946
}

message LocalResponseNormalization {
  int64 num_dims = 1;
  int64 num_channels = 2;
  string dims = 3;  //e.g, "2 2 2"
  int64 window_width = 4;
  double lrn_alpha = 5;
  double lrn_beta = 6;
  double lrn_k = 7;
}

message Dropout {
  double keep_prob = 2;  //default: 0.5
}

//////////////////
// Input Layers //
//////////////////
message InputDistributedMiniBatchParallelIO {
}

message InputPartitionedMiniBatchParallelIO {
}

//////////////////////
// transform Layers //
//////////////////////
message Pooling {
  int64 num_dims = 1;
  int64 num_channels = 2;
  string input_dims = 3; //should be space-separated list, e.g, "2 2 3"
  string pool_dims = 4; //should be space-separated list, e.g, "2 2 3"
  string pool_pads = 5; //should be space-separated list, e.g, "2 2 3"
  string pool_strides = 6; //should be space-separated list, e.g, "2 2 3"

  //pool_mode should be one of: max, average, average_no_pad
  //see: lbann/include/lbann/lbann_base.hpp
  string pool_mode = 7;
}

/////////////////////
// learning Layers //
/////////////////////
message FullyConnected {
  int64 num_neurons = 2;
  string weight_initialization = 5;
  bool has_bias = 6;
  double l2_regularization_factor = 10;
}
message Convolution {
  int64 num_dims = 1;
  int64 num_input_channels = 2;
  string input_dims = 3; //should be space-separated list, e.g, "2 2 3"
  int64 num_output_channels = 4;
  string filter_dims = 5; //should be space-separated list, e.g, "2 2 3"
  string conv_pads = 6;  //should be space-separated list, e.g, "2 2 3"
  string conv_strides = 7; //should be space-separated list, e.g, "2 2 3"
  int64 mini_batch_size = 8;
  string weight_initialization = 9;
  double l2_regularization_factor = 10;
}

///////////////////
// Target Layers //
///////////////////
message TargetDistributedMinibatchParallelIO {
  bool shared_data_reader = 2;
  bool for_regression = 3;
}

message TargetPartitionedMinibatchParallelIO {
  bool shared_data_reader = 2;
  bool for_regression = 3;
}

message TargetReconstruction {
  int64 original_layer = 1;
}

//========================================================================
// end of Layer types
//========================================================================
